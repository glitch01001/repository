{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ this is the current working version with query __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: VM-LESSQL04\n",
      "Database: LOPR\n",
      "Number of rows returned from SQL query: 85182\n",
      "Total rows included: 80402\n",
      "Total rows excluded: 4780\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1f464924810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import time\n",
    "import requests\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "import dash\n",
    "from dash import html, dcc, Input, Output\n",
    "\n",
    "# --- New Credentials (hard-coded) ---\n",
    "server = \"VM-LESSQL04\"      # Replace with your new server address\n",
    "database = \"LOPR\"       # Replace with your new database name\n",
    "# username = \"\"            # Replace with your new username\n",
    "# password = \"\"            # Replace with your new password\n",
    "\n",
    "# Optional: Print out the credentials for debugging purposes\n",
    "print(f\"Server: {server}\")\n",
    "print(f\"Database: {database}\")\n",
    "# print(f\"Username: {username}\")\n",
    "\n",
    "# --- Create the ODBC connection string and URL-encode it ---\n",
    "params = urllib.parse.quote_plus(\n",
    "    \"DRIVER={SQL Server};\"\n",
    "    f\"SERVER={server};\"\n",
    "    f\"DATABASE={database};\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "# --- Create SQLAlchemy engine using the pyodbc driver ---\n",
    "engine = create_engine(f\"mssql+pyodbc:///?odbc_connect={params}\")\n",
    "\n",
    "# SQL query (unchanged)\n",
    "sql_query = \"\"\"\n",
    "WITH Temp_sv302SigleReturn AS (\n",
    "    SELECT\n",
    "        sv302.[Service_Call_ID],\n",
    "        sv302.[System],\n",
    "        sv302.[Task_Code],\n",
    "        TRY_CAST(sv302.[Task_User_Define13] AS INT) AS [Task_User_Define13],\n",
    "        sv302.[Task_User_Define5],\n",
    "        CAST(sv302.[CREATDDT] AS DATE) AS [CREATDDT],\n",
    "        CAST(sv302.[Task_User_Define9] AS DATE) AS [Task_User_Define9],\n",
    "        CAST(sv302.[Task_User_Define10] AS DATE) AS [Task_User_Define10],\n",
    "        ROW_NUMBER() OVER (\n",
    "            PARTITION BY sv302.[Service_Call_ID]\n",
    "            ORDER BY sv302.[DEX_ROW_ID] DESC\n",
    "        ) AS [ROW_NUMBER]\n",
    "    FROM [VM-LESSQL04].[LOPR].[dbo].[SV00302] sv302\n",
    "    WHERE \n",
    "        sv302.[Major] = 'TRAP'\n",
    "        AND sv302.[Equipment_ID] NOT LIKE 'FEES'\n",
    "        AND sv302.[System] IS NOT NULL\n",
    "        AND sv302.[Task_Code] NOT LIKE 'QT-TRCH'\n",
    "        AND (sv302.[Service_Call_ID] LIKE '25%' OR sv302.[Service_Call_ID] LIKE '24%')\n",
    "),\n",
    "ExistingServices AS (\n",
    "    SELECT \n",
    "        LEFT(svc.[Region], 3) AS [SITE],\n",
    "        RIGHT('000000' + CAST(svc.[Customer_Number] AS VARCHAR(6)), 6)\n",
    "            + RIGHT('00000' + CAST(svc.[Address_Code] AS VARCHAR(5)), 5) AS [ACCOUNT],\n",
    "        ts.[System] AS [LOB],\n",
    "        CASE \n",
    "            WHEN svc.[Complete] = 0 THEN 'not routed'\n",
    "            WHEN svc.[Complete] = 1 THEN 'routed'\n",
    "            WHEN svc.[Complete] = 2 THEN 'serviced'\n",
    "            WHEN svc.[Complete] IN (3, 4, 9) THEN 'complete'\n",
    "            ELSE 'unknown'\n",
    "        END AS [CompletionStatus],\n",
    "        ts.[Task_User_Define5] AS [FREQ],\n",
    "        ts.[Task_User_Define10] AS [NSD],\n",
    "        ts.[Task_User_Define13] AS [GALLONS],\n",
    "        svc.[Customer_Number],\n",
    "        svc.[Address_Code]\n",
    "    /*svc*/\n",
    "    FROM [VM-TMWDB].[Services].[dbo].[Services] svc\n",
    "    /*ts*/\n",
    "    INNER JOIN Temp_sv302SigleReturn ts\n",
    "        ON svc.[Service_Call_ID] = ts.[Service_Call_ID]\n",
    "        AND ts.[ROW_NUMBER] = 1\n",
    "    /*sv500*/\n",
    "    INNER JOIN [VM-LESSQL04].[LOPR].[dbo].[SV00500] sv500\n",
    "        ON svc.[Customer_Number] = sv500.[CUSTNMBR]\n",
    "        AND svc.[Address_Code] = sv500.[ADRSCODE]\n",
    "    /*svcData*/\n",
    "    LEFT JOIN [VM-TMWDB].[Services].[dbo].[Services_Data] svcData\n",
    "        ON svc.[Service_Call_ID] = svcData.[Service_Call_ID]\n",
    "        AND svc.[Appointment] = svcData.[Appointment]\n",
    "    /*sv301*/\n",
    "    LEFT JOIN [VM-LESSQL04].[LOPR].[dbo].[SV00301] sv301\n",
    "        ON svc.[Service_Call_ID] = LTRIM(RTRIM(sv301.[Service_Call_ID]))\n",
    "        AND svc.[Appointment] = CAST(LTRIM(RTRIM(sv301.[Appointment])) AS INT)\n",
    "    WHERE \n",
    "        (svc.[Complete] = 0 OR svc.[Complete] = 1)\n",
    "        AND (svcData.[ApprovedBy] IS NULL OR svcData.[ApprovedBy] <> 'WS.Deleted')\n",
    "        AND sv500.[HOLD] = 0\n",
    "        AND sv301.[Appointment_Status] NOT LIKE 'ON HOLD'\n",
    "        AND (ts.[System] LIKE 'GRTR' OR ts.[System] LIKE 'OWS' OR ts.[System] LIKE 'GRIT' OR ts.[System] LIKE 'UCO')\n",
    "),\n",
    "ProjectionServices AS (\n",
    "    SELECT DISTINCT\n",
    "        LEFT(sv200.[Divisions], 3) AS [SITE],\n",
    "        RIGHT('000000' + CAST(sv582.[CUSTNMBR] AS VARCHAR(6)), 6)\n",
    "            + RIGHT('00000' + CAST(sv582.[ADRSCODE] AS VARCHAR(5)), 5) AS [ACCOUNT],\n",
    "        sv582.[System] AS [LOB],\n",
    "        'projection' AS [CompletionStatus],\n",
    "        sv582.[Task_User_Define5] AS [FREQ],\n",
    "        CAST(sv582.[Task_User_Define10] AS DATE) AS [NSD],\n",
    "        sv582.[Task_User_Define13] AS [GALLONS],\n",
    "        sv582.[CUSTNMBR] AS [Customer_Number],\n",
    "        sv582.[ADRSCODE] AS [Address_Code]\n",
    "    /*sv582*/\n",
    "    FROM [VM-LESSQL04].[LOPR].[dbo].[SV00582] sv582\n",
    "    /*sv560*/\n",
    "    INNER JOIN [VM-LESSQL04].[LOPR].[dbo].[SV00560] sv560\n",
    "        ON sv560.Task_Code = sv582.Task_Code\n",
    "        AND sv560.Major = 'TRAP'\n",
    "    /*sv200*/\n",
    "    INNER JOIN [VM-LESSQL04].[LOPR].[dbo].[SV00200] sv200\n",
    "        ON sv200.[CUSTNMBR] = sv582.[CUSTNMBR]\n",
    "        AND sv200.[ADRSCODE] = sv582.[ADRSCODE]\n",
    "    /*sv500*/\n",
    "    INNER JOIN [VM-LESSQL04].[LOPR].[dbo].[SV00500] sv500\n",
    "        ON sv582.[CUSTNMBR] = sv500.[CUSTNMBR]\n",
    "        AND sv582.[ADRSCODE] = sv500.[ADRSCODE]\n",
    "    WHERE \n",
    "        sv582.[Task_User_Define5] <> 0\n",
    "        AND sv200.[WSReserved_CB1] = 0\n",
    "        AND sv500.[HOLD] = 0\n",
    "        AND sv560.[Major] = 'TRAP'\n",
    "        AND sv582.[Task_User_Define10] > '2024-01-01'\n",
    "        AND sv582.[Task_User_Define9] > '2024-01-01'\n",
    "        AND (sv582.[System] LIKE 'GRTR' OR sv582.[System] LIKE 'OWS' OR sv582.[System] LIKE 'GRIT' OR sv582.[System] LIKE 'UCO')\n",
    "        AND sv582.[System] NOT LIKE 'GREASEFEES'\n",
    "        AND sv582.[System] IS NOT NULL\n",
    "        AND sv582.[System] NOT LIKE '               '\n",
    "        AND sv582.[Task_Code] NOT LIKE 'QT-TRCH'\n",
    "        AND NOT EXISTS (\n",
    "            SELECT 1 \n",
    "            FROM ExistingServices es \n",
    "            WHERE es.[Customer_Number] = sv582.[CUSTNMBR]\n",
    "            AND es.[Address_Code] = sv582.[ADRSCODE]\n",
    "        )\n",
    ")\n",
    "SELECT \n",
    "    SITE, \n",
    "    ACCOUNT, \n",
    "    LOB, \n",
    "    CompletionStatus, \n",
    "    FREQ, \n",
    "    NSD, \n",
    "    GALLONS, \n",
    "    Customer_Number, \n",
    "    Address_Code\n",
    "FROM ExistingServices\n",
    "UNION ALL\n",
    "SELECT \n",
    "    SITE, \n",
    "    ACCOUNT, \n",
    "    LOB, \n",
    "    CompletionStatus, \n",
    "    FREQ, \n",
    "    NSD, \n",
    "    GALLONS, \n",
    "    Customer_Number, \n",
    "    Address_Code\n",
    "FROM ProjectionServices;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Fetch data using the SQLAlchemy engine\n",
    "df = pd.read_sql(sql_query, engine)\n",
    "print(f\"Number of rows returned from SQL query: {len(df)}\")\n",
    "\n",
    "# Convert FREQ, NSD, and GALLONS to appropriate data types\n",
    "df['FREQ'] = pd.to_numeric(df['FREQ'], errors='coerce')\n",
    "df['NSD'] = pd.to_datetime(df['NSD'], errors='coerce')\n",
    "df['GALLONS'] = pd.to_numeric(df['GALLONS'], errors='coerce')\n",
    "\n",
    "# Extract unique LOB values from the query\n",
    "lob_list = df['LOB'].unique().tolist()\n",
    "\n",
    "# Get today's date and ISO week number\n",
    "today = pd.Timestamp('today').normalize()\n",
    "current_week = today.isocalendar()[1]\n",
    "current_year = today.year\n",
    "\n",
    "# Global parameter for projection\n",
    "predict = 26\n",
    "weekCodes = list(range(1, predict + 1))\n",
    "\n",
    "# Calculate base Sunday date: find the upcoming Sunday\n",
    "# days_until_sunday = (6 - today.weekday()) % 7\n",
    "# base_sunday = today + pd.Timedelta(days=days_until_sunday)\n",
    "\n",
    "days_since_sunday = (today.weekday() + 1) % 7\n",
    "base_sunday = today - pd.Timedelta(days=days_since_sunday)\n",
    "\n",
    "# Create list of Sunday dates for each forecast week\n",
    "sunday_dates = [(base_sunday + pd.Timedelta(weeks=i)).strftime(\"%Y-%m-%d\") for i in range(predict)]\n",
    "\n",
    "# Function to create the source projection using a fixed count\n",
    "def create_customer_projection(start_week_offset, frequency, count_value):\n",
    "    projection = pd.Series(0, index=weekCodes)\n",
    "    for week in range(start_week_offset, predict + 1, frequency):\n",
    "        projection[week] = count_value\n",
    "    return projection\n",
    "\n",
    "# Generate projections for each customer (using a count for SC)\n",
    "source_projections = []\n",
    "included_rows = 0\n",
    "excluded_rows = 0\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        # Existing check for NSD in the past\n",
    "        if row['NSD'] < today and row['CompletionStatus'] in ['not routed', 'routed'] and row['CompletionStatus'] != 'projection':\n",
    "            start_week_offset = 1\n",
    "        else:\n",
    "            # Calculate the NSD's ISO week; adjust if NSD is next year.\n",
    "            nsd_week = row['NSD'].isocalendar()[1]\n",
    "            nsd_year = row['NSD'].year\n",
    "            if nsd_year > current_year:\n",
    "                nsd_week += 52\n",
    "            week_difference = nsd_week - current_week\n",
    "\n",
    "            frequency = int(row['FREQ'])\n",
    "            # Determine skew based on FREQ using strict inequalities\n",
    "            if frequency < 10:\n",
    "                skew = 1\n",
    "            elif 10 < frequency < 17:\n",
    "                skew = 2\n",
    "            elif frequency > 17:\n",
    "                skew = 4\n",
    "            else:\n",
    "                # Handle edge cases: for FREQ exactly 10 or 17, choose a default:\n",
    "                # For example, assign skew=1 if FREQ==10 and skew=2 if FREQ==17.\n",
    "                skew = 1 if frequency == 10 else 2\n",
    "\n",
    "            # Adjust start_week_offset by subtracting the skew\n",
    "            start_week_offset = max(1, week_difference + 1 - skew)\n",
    "\n",
    "            if start_week_offset < 1 or start_week_offset > predict:\n",
    "                excluded_rows += 1\n",
    "                continue\n",
    "\n",
    "        service_count = 1  \n",
    "        projection = create_customer_projection(start_week_offset, frequency, service_count)\n",
    "        source_projections.append((row['SITE'], row['LOB'], projection))\n",
    "        included_rows += 1\n",
    "\n",
    "    except Exception:\n",
    "        excluded_rows += 1\n",
    "        continue\n",
    "\n",
    "\n",
    "print(f\"Total rows included: {included_rows}\")\n",
    "print(f\"Total rows excluded: {excluded_rows}\")\n",
    "\n",
    "# Convert projections to DataFrame, including LOB\n",
    "projection_df = pd.DataFrame([\n",
    "    {'SITE': proj[0], 'LOB': proj[1], **proj[2].to_dict()} for proj in source_projections\n",
    "])\n",
    "\n",
    "# Group by SITE and LOB and sum the projections\n",
    "grouped_source = projection_df.groupby(['SITE', 'LOB'])[weekCodes].sum().reset_index()\n",
    "\n",
    "# Create the Site-to-Region mapping DataFrame\n",
    "site_region_df = pd.DataFrame({\n",
    "    'SITE': ['ATL', 'ATB', 'AUB', 'AUS', 'BAL', 'BIR', 'CHR', 'CHI', 'CLE', 'DAL', 'DEN', 'HOU',\n",
    "             'JAX', 'KAN', 'KNO', 'LSV', 'LIT', 'LUF', 'MEM', 'MIA', 'MIL', 'MIN', 'MOB',\n",
    "             'NAS', 'NOR', 'NCA', 'OKC', 'PHI', 'PHX', 'PIT', 'POR', 'RGV', 'SAN', 'SND',\n",
    "             'SEA', 'SHR', 'SCA', 'STL', 'TAM', 'WSM'],\n",
    "    'Region': ['East', 'North', 'North', 'West', 'North', 'East', 'East', 'North', 'North', 'West',\n",
    "               'West', 'West', 'East', 'North', 'East', 'West', 'East', 'West', 'East', 'East',\n",
    "               'North', 'North', 'East', 'East', 'East', 'West', 'West', 'East', 'West', 'North',\n",
    "               'West', 'West', 'West', 'West', 'West', 'East', 'West', 'North', 'East', 'East']\n",
    "})\n",
    "\n",
    "# Merge grouped_source with site_region_df on SITE\n",
    "grouped_source = grouped_source.merge(site_region_df, on='SITE', how='left')\n",
    "\n",
    "# Get lists for dropdowns\n",
    "site_list = grouped_source['SITE'].unique().tolist()\n",
    "region_list = site_region_df['Region'].unique().tolist()\n",
    "\n",
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Define the app layout with added LOB dropdown\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "        html.Label('Select Regions:', style={'color': '#00ff41'}),\n",
    "        dcc.Dropdown(\n",
    "            id='region-dropdown',\n",
    "            options=[{'label': region, 'value': region} for region in sorted(region_list)],\n",
    "            value=[],\n",
    "            multi=True,\n",
    "            placeholder=\"Select Regions\",\n",
    "            style={'backgroundColor': 'rgb(30, 30, 30)', 'color': 'green', 'width': '100%'}\n",
    "        )\n",
    "    ], style={'width': '30%', 'display': 'inline-block', 'verticalAlign': 'top'}),\n",
    "    \n",
    "    html.Div([\n",
    "        html.Label('Select LOB:', style={'color': '#00ff41'}),\n",
    "        dcc.Dropdown(\n",
    "            id='lob-dropdown',\n",
    "            options=[{'label': 'ALL', 'value': 'ALL'}] + [{'label': lob, 'value': lob} for lob in sorted(lob_list)],\n",
    "            value=[],\n",
    "            multi=True,\n",
    "            placeholder=\"Select LOB\",\n",
    "            style={'backgroundColor': 'rgb(30, 30, 30)', 'color': 'green', 'width': '100%'}\n",
    "        )\n",
    "    ], style={'width': '30%', 'display': 'inline-block', 'marginLeft': '2%', 'verticalAlign': 'top'}),\n",
    "\n",
    "    html.Div([\n",
    "        html.Label('Select Sites:', style={'color': '#00ff41'}),\n",
    "        dcc.Dropdown(\n",
    "            id='site-dropdown',\n",
    "            options=[{'label': site, 'value': site} for site in sorted(site_list)],\n",
    "            value=site_list[:5],\n",
    "            multi=True,\n",
    "            placeholder=\"Select Sites\",\n",
    "            style={'backgroundColor': 'rgb(30, 30, 30)', 'color': 'green', 'width': '100%'}\n",
    "        )\n",
    "    ], style={'width': '30%', 'display': 'inline-block', 'marginLeft': '2%', 'verticalAlign': 'top'}),\n",
    "\n",
    "    dcc.Graph(id='graph', style={'height': '550px'}) # Adjust height as needed\n",
    "], style={'backgroundColor': 'rgb(30, 30, 30)', 'padding': '10px'})\n",
    "\n",
    "# Figure creation function using filtered grouped_source data with Sunday dates on the x-axis\n",
    "def create_figure(filtered_data):\n",
    "    fig = go.Figure()\n",
    "    # Exclude week 1 from the visualization by slicing weekCodes and sunday_dates\n",
    "    plot_weekCodes = weekCodes[1:]  # assuming weekCodes is something like [1, 2, ..., predict]\n",
    "    plot_sunday_dates = sunday_dates[1:]\n",
    "    \n",
    "    for _, row in filtered_data.iterrows():\n",
    "        site = row['SITE']\n",
    "        # Convert the projection row to a list, then slice off the first element\n",
    "        y_values = [row[week] for week in weekCodes][1:]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=plot_sunday_dates,  # use the modified sunday_dates excluding the current week\n",
    "            y=y_values,\n",
    "            mode='lines+markers',\n",
    "            name=site,\n",
    "            line=dict(dash='solid', shape='spline'),\n",
    "            visible=True\n",
    "        ))\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Sunday Date\",\n",
    "        yaxis_title=\"Service Count\",\n",
    "        xaxis=dict(\n",
    "            tickmode='array',\n",
    "            tickvals=plot_sunday_dates,\n",
    "            ticktext=plot_sunday_dates,\n",
    "            gridcolor='gray',\n",
    "            zerolinecolor='gray',\n",
    "            gridwidth=0.5,\n",
    "            type='category'\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            gridcolor='gray',\n",
    "            zerolinecolor='gray',\n",
    "            gridwidth=0.5,\n",
    "        ),\n",
    "        paper_bgcolor='rgb(30, 30, 30)',\n",
    "        plot_bgcolor='rgb(40, 40, 40)',\n",
    "        font=dict(color='#00ff41'),\n",
    "        hovermode='x',\n",
    "        legend_title=\"Site\",\n",
    "        height=900,\n",
    "        margin=dict(l=40, r=20, t=20, b=40)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "# Callback to update the graph based on selected Sites, Regions, and LOB\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input('site-dropdown', 'value'),\n",
    "     Input('region-dropdown', 'value'),\n",
    "     Input('lob-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_sites, selected_regions, selected_lobs):\n",
    "    filtered = grouped_source.copy()\n",
    "    if selected_regions:\n",
    "        sites_in_regions = site_region_df[site_region_df['Region'].isin(selected_regions)]['SITE']\n",
    "        filtered = filtered[filtered['SITE'].isin(sites_in_regions)]\n",
    "    \n",
    "    # Handle LOB filtering:\n",
    "    if selected_lobs:\n",
    "        if 'ALL' not in selected_lobs:\n",
    "            filtered = filtered[filtered['LOB'].isin(selected_lobs)]\n",
    "        else:\n",
    "            # When \"ALL\" is selected, aggregate across LOBs for each SITE\n",
    "            # Group by SITE and sum all the weekly count columns\n",
    "            filtered = filtered.groupby('SITE', as_index=False)[weekCodes].sum()\n",
    "            # Optionally add a dummy LOB column to label the aggregated data\n",
    "            filtered['LOB'] = 'ALL'\n",
    "    \n",
    "    if selected_sites:\n",
    "        filtered = filtered[filtered['SITE'].isin(selected_sites)]\n",
    "    \n",
    "    if filtered.empty:\n",
    "        return go.Figure(layout={\n",
    "            'paper_bgcolor': 'rgb(30, 30, 30)',\n",
    "            'plot_bgcolor': 'rgb(40, 40, 40)',\n",
    "            'font': {'color': 'green'},\n",
    "            'xaxis': {'visible': False},\n",
    "            'yaxis': {'visible': False},\n",
    "            'annotations': [{\n",
    "                'text': 'Please select at least one site, region, or LOB.',\n",
    "                'xref': 'paper',\n",
    "                'yref': 'paper',\n",
    "                'showarrow': False,\n",
    "                'font': {'size': 20, 'color': 'green'}\n",
    "            }]\n",
    "        })\n",
    "    else:\n",
    "        return create_figure(filtered)\n",
    "\n",
    "# Run the Dash app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ output HTML files __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file for Region 'East' and LOB 'GRIT           ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.East.GRIT___________.html\n",
      "Saved file for Region 'East' and LOB 'GRTR           ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.East.GRTR___________.html\n",
      "Saved file for Region 'East' and LOB 'OWS            ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.East.OWS____________.html\n",
      "Saved file for Region 'East' and LOB 'UCO            ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.East.UCO____________.html\n",
      "Saved file for Region 'North' and LOB 'GRIT           ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.North.GRIT___________.html\n",
      "Saved file for Region 'North' and LOB 'GRTR           ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.North.GRTR___________.html\n",
      "Saved file for Region 'North' and LOB 'OWS            ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.North.OWS____________.html\n",
      "Saved file for Region 'North' and LOB 'UCO            ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.North.UCO____________.html\n",
      "Saved file for Region 'West' and LOB 'GRIT           ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.West.GRIT___________.html\n",
      "Saved file for Region 'West' and LOB 'GRTR           ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.West.GRTR___________.html\n",
      "Saved file for Region 'West' and LOB 'OWS            ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.West.OWS____________.html\n",
      "Saved file for Region 'West' and LOB 'UCO            ': C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\projection_figure.West.UCO____________.html\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set the output directory for exported HTML files\n",
    "output_directory = r'C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Get the unique Regions and LOBs from the data\n",
    "unique_regions = grouped_source['Region'].dropna().unique().tolist()\n",
    "unique_lobs = grouped_source['LOB'].dropna().unique().tolist()\n",
    "\n",
    "# Loop through each combination of Region and LOB\n",
    "for region in sorted(unique_regions):\n",
    "    for lob in sorted(unique_lobs):\n",
    "        # Filter the data for the current combination\n",
    "        filtered_data = grouped_source[(grouped_source['Region'] == region) &\n",
    "                                        (grouped_source['LOB'] == lob)]\n",
    "        if filtered_data.empty:\n",
    "            print(f\"No data for Region '{region}' and LOB '{lob}'. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Create the figure using your existing function\n",
    "        fig = create_figure(filtered_data)\n",
    "        \n",
    "        # Construct an output file name; replace spaces with underscores if necessary\n",
    "        safe_region = region.replace(\" \", \"_\")\n",
    "        safe_lob = lob.replace(\" \", \"_\")\n",
    "        output_file_name = f\"projection_figure.{safe_region}.{safe_lob}.html\"\n",
    "        output_file_path = os.path.join(output_directory, output_file_name)\n",
    "        \n",
    "        # Save the figure as an HTML file\n",
    "        fig.write_html(output_file_path)\n",
    "        print(f\"Saved file for Region '{region}' and LOB '{lob}': {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Plotly figure exported to: C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\static_plotly_figure.html\n"
     ]
    }
   ],
   "source": [
    "import plotly.io as pio\n",
    "\n",
    "# Assuming 'fig' is your Plotly figure you want to export\n",
    "output_file = r'C:\\Users\\aaron.eades\\OneDrive - Liquid Environmental Solutions\\Documents\\Programing\\Python\\Automated Density\\exports\\static_plotly_figure.html'\n",
    "pio.write_html(fig, file=output_file, auto_open=True)\n",
    "print(\"Static Plotly figure exported to:\", output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
